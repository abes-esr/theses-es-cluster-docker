# theses-es-cluster-docker

(travail en cours)

Configuration docker üê≥ pour d√©ployer un n≈ìud du cluster elasticsearch de theses.fr (voir aussi le d√©p√¥t [``theses-docker``](https://github.com/abes-esr/theses-docker)). 

## Pr√©requis


- docker
- docker-compose
- r√©glages ``vm.max_map_count`` pour elasticsearch (cf [FAQ pour les d√©tails du r√©glage](https://github.com/abes-esr/theses-docker/blob/develop/README-faq.md#comment-r%C3%A9gler-vmmax_map_count-pour-elasticsearch-))

## Installation

Pour int√©grer un noeud supl√©mentaire au cluster elasticsearch de theses.fr, voici la marche √† suivre.

On suppose ci-dessous un d√©ploiement de 3 noeuds sur les serveurs suivants (mais on peut extrapoler pour cr√©er 4, 5, ou 6 noeuds si n√©cessaire) :
- ``diplotaxis1-test``
- ``diplotaxis2-test``
- ``diplotaxis3-test``

Le d√©ploiement d'un nouveau noeud elasticsearch suppose un d√©ploiement pr√©alable de l'application theses.fr (voir [``theses-docker``](https://github.com/abes-esr/theses-docker)) qui embarque en fait le premier noeud elasticsearch. L'installation un peu particuli√®re de ce premier noeud est d√©crite dans la [premi√®re partie de l'installation](#installation--serveur-1--noeud-1).


### Installation : Serveur 1 / Noeud 1

Sur le premier serveur ``diplotaxis1-test`` on va installer le premier noeud elasticsearch en compagnie de toute la pile logicielle de theses.fr. Il y aura donc sur ce premier serveur tous les modules de theses.fr ainsi que le premier noeud du cluster elasticsearch et aussi le kibana d'administration.

Pour installer ce noeud, il faut se reporter √† la [section installation du d√©p√¥t ``theses-docker``](README.md#installation).

Ensuite sur ce premier noeud, la seule chose √† r√©gler concerne les param√®tres suivants dans le ``.env`` (ce qui est important c'est de bien choisir le num√©ro "01" pour le num√©ro du noeud) :
```env
ELK_CLUSTER_NODE_NUMBER=01
ELK_CLUSTER_DISCOVER_SEED_HOSTS=diplotaxis1-test:10305,diplotaxis2-test:10305,diplotaxis3-test:10305
ELK_CLUSTER_INITIAL_MASTER_NODES=theses-es01,theses-es02,theses-es03
```

Vous devez ensuite lancer l'application classiquement avec cette commande :
```bash
cd /opt/pod/theses-docker/
docker-compose up -d
```

### Installation : Serveurs 2 & 3 / Noeuds 2 & 3

Le second et le troisi√®me noeud elasticsearch de theses.fr sont respectivement d√©ploy√©s sur ``diplotaxis2-test`` et ``diplotaxis3-test`` (cette documentation permet d'extrapoler pour augmenter √† 4, 5 ou 6 noeuds elasticsearch si c'√©tait un jour n√©cessaire). La configuration n√©cessaire pour d√©ployer ces noeuds supl√©mentaires est contenu dans ce pr√©sent d√©p√¥t. Voici les commandes √† lancer sur les diff√©rents serveurs pour installer les noeuds.

```bash
cd /opt/pod/
git clone https://github.com/abes-esr/theses-es-cluster-docker.git

cd /opt/pod/theses-es-cluster-docker/
mkdir -p volumes/theses-elasticsearch/            && chmod 777 volumes/theses-elasticsearch/
```

Ensuite il faut cr√©er un fichier ``/opt/pod/theses-es-cluster-docker/.env`` en partant du [mod√®le ``.env-dist``](./.env-dist) :
```bash
cd /opt/pod/theses-es-cluster-docker/
cp .env-dist .env
```

R√©gler surtout les variables suivantes en prenant soins d'incr√©menter le n¬∞ du noeud dans ``ELK_CLUSTER_NODE_NUMBER`` sous la forme ``XX`` :
```env
ELK_CLUSTER_NODE_NUMBER=02
ELK_CLUSTER_DISCOVER_SEED_HOSTS=diplotaxis1-test:10305,diplotaxis2-test:10305,diplotaxis3-test:10305
ELK_CLUSTER_INITIAL_MASTER_NODES=theses-es01,theses-es02,theses-es03
```

Et finalement on peut d√©marrer le noeud elasticsearch qui rejoindra alors le cluster elasticsearch de theses.fr :
```bash
cd /opt/pod/theses-es-cluster-docker/
docker-compose up -d
```

## Supervision

Pour savoir si le cluster √† correctement d√©marr√© avec ses 3 noeuds, tapez ceci:
```bash
 curl http://diplotaxis1-test:10302/_cluster/health?pretty
```

Si tout c'est bien pass√©, vous devriez avoir un retour de ce type :
```json
{
  "cluster_name" : "theses-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 3,
  "number_of_data_nodes" : 3,
  "active_primary_shards" : 1,
  "active_shards" : 3,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
```

On peut √©galement observer les logs des noeuds quand un noeud rejoint le cluster :
```json
# cot√© noeud 1
{
 "@timestamp":"2022-07-27T14:56:55.732Z", "log.level": "INFO",
  "message":"added {{theses-es02}{sH6jSIdMRRyQ5JVowchsyQ}{Sx1tZYh-Rca8nt3GQ2Z-ng}{theses-es02}{172.31.0.2}{172.31.0.2:9300}{cdfhilmrstw}}, term: 5, version: 158, reason: Publication{term=5, version=158}",
  "ecs.version": "1.2.0","service.name":"ES_ECS","event.dataset":"elasticsearch.server","process.thread.name":"elasticsearch[theses-es01][clusterApplierService#updateTask][T#1]",
  "log.logger":"org.elasticsearch.cluster.service.ClusterApplierService",
  "elasticsearch.cluster.uuid":"Y4rayRuGRkasvpxF0DvGTg",
  "elasticsearch.node.id":"I8qD98AIRRyidBDEs_WAqQ",
  "elasticsearch.node.name":"theses-es01",
  "elasticsearch.cluster.name":"theses-cluster"
}

# cot√© noeud 2
{
  "@timestamp":"2022-07-27T14:56:55.223Z", "log.level": "INFO",
  "message":"master node changed {previous [], current [{theses-es01}{I8qD98AIRRyidBDEs_WAqQ}{8Bc5pUJnTmyG6qNhZDIFTw}{theses-es01}{172.31.0.6}{172.31.0.6:9300}{cdfhilmrstw}]}, added {{theses-es01}{I8qD98AIRRyidBDEs_WAqQ}{8Bc5pUJnTmyG6qNhZDIFTw}{theses-es01}{172.31.0.6}{172.31.0.6:9300}{cdfhilmrstw}}, term: 5, version: 158, reason: ApplyCommitRequest{term=5, version=158, sourceNode={theses-es01}{I8qD98AIRRyidBDEs_WAqQ}{8Bc5pUJnTmyG6qNhZDIFTw}{theses-es01}{172.31.0.6}{172.31.0.6:9300}{cdfhilmrstw}{ml.machine_memory=1073741824, ml.max_jvm_size=536870912, xpack.installed=true}}",
  "ecs.version": "1.2.0","service.name":"ES_ECS","event.dataset":"elasticsearch.server","process.thread.name":"elasticsearch[theses-es02][clusterApplierService#updateTask][T#1]",
  "log.logger":"org.elasticsearch.cluster.service.ClusterApplierService",
  "elasticsearch.node.name":"theses-es02",
  "elasticsearch.cluster.name":"theses-cluster"
}
```


## M√©mo

L'authentification ELASTIC_PASSWORD n'est utilis√©e que pour l'API JSON d'elasticsearch. La communication entre les diff√©rents noeuds du cluster elasticsearch est r√©alis√©e en se basant sur le syst√®me de certificat qui est utilis√© via la directive ``xpack.security.transport.ssl.enabled=true``. A noter que dans le cas o√π la securit√© est d√©sactiv√©e, la variable ELASTIC_PASSWORD n'est pas utilis√©e.

Le port 9300 est utilis√© (protocole binaire) pour faire communiquer les diff√©rents noeuds du cluster elasticsearch (attention √† bien l'exposer sur les diff√©rents serveurs). Ce n'est pas le port 9200 qui lui est utilis√© pour exposer l'API classique d'elasticsearch. Exemple de la configuration o√π ce port 9300 est utilis√© :  
``ELK_CLUSTER_DISCOVER_SEED_HOSTS=theses-elasticsearch-01:9300,theses-elasticsearch-02:9300``
